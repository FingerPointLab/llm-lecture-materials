{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-community tiktoken faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DF31AzPjXMe",
        "outputId": "e7836f3a-8b14-4318-fc5a-28e30738551c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDWHwB_vQlcY"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# 🔹 OpenAI API 키 설정 (환경변수 또는 직접 입력)\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"openai-api-key\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/FingerPointLab/llm-lecture-materials/refs/heads/main/voc_example.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azWLLNapliJd",
        "outputId": "55950a66-efc6-43b7-f1a0-0af8633b5f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 10:25:17--  https://raw.githubusercontent.com/FingerPointLab/llm-lecture-materials/refs/heads/main/voc_example.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2306 (2.3K) [text/plain]\n",
            "Saving to: ‘voc_example.txt.1’\n",
            "\n",
            "\rvoc_example.txt.1     0%[                    ]       0  --.-KB/s               \rvoc_example.txt.1   100%[===================>]   2.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-24 10:25:17 (27.6 MB/s) - ‘voc_example.txt.1’ saved [2306/2306]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 로딩\n",
        "loader = TextLoader('voc_example.txt')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "g6mOwoyUkRdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 텍스트 분할 (Chunking)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10, separators=[\"\\n\\n\"])\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Ib8VnMjR4U",
        "outputId": "4d4ea14f-1e25-4c85-eba8-8041cac664ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'voc_example.txt'}, page_content='[고객1]\\n배송이 너무 느립니다. 일주일이나 걸렸어요. 이런 식이면 다음부터는 다른 쇼핑몰을 이용해야 할 것 같네요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객2]\\n제품 포장은 잘 되어 있었지만, 설명서가 너무 불친절합니다. 사용법이 이해가 안 가서 검색해봤어요. 초보자 입장에선 너무 어렵습니다.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객3]\\n배송은 빠르게 왔는데, 박스가 찌그러져 있었습니다. 선물용이라 포장이 중요했는데 좀 아쉽네요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객4]\\n제품은 괜찮은데 고객센터 연결이 너무 어렵습니다. 10번 넘게 전화해서 겨우 연결했어요. 상담원은 친절했지만 대기 시간이 너무 길었습니다.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객5]\\n설명서에 나와 있는 기능이 실제 제품에는 없네요. 사기당한 기분입니다. 반품 요청하고 싶은데 절차가 너무 복잡합니다.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객6]\\n택배가 도착했는데 문 앞에 아무런 연락 없이 그냥 두고 갔어요. 분실 우려가 있어서 불안했습니다.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객7]\\n주문한 날짜 기준으로 정확히 7일 만에 도착했어요. 요즘 시대에 너무 느린 거 아닌가요?'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객8]\\n설명서가 외국어로만 되어 있어서 내용을 이해하기 어려웠습니다. 한글 설명서도 같이 제공해 주세요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객9]\\n제품 설명서가 너무 간단해서 어떤 기능이 있는지 제대로 알 수 없었습니다. 상세한 설명이 필요합니다.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객10]\\n배송 박스가 너무 커서 불편했습니다. 작은 물건 하나 보내는데 왜 이렇게 큰 상자를 쓰는지 모르겠어요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객11]\\n제품은 만족스러운데 설명서에 오타가 많아서 신뢰가 떨어졌습니다. 검수 좀 철저히 해주세요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객12]\\n배송이 두 번 나눠서 왔습니다. 한 번에 보내주셨으면 더 편했을 것 같아요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객13]\\n설명서에 그림이 부족해서 조립 과정이 너무 헷갈렸어요. 동영상 안내라도 있었으면 좋겠네요.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객14]\\n주문 후 배송 준비 상태로 며칠이나 있다가 갑자기 발송되더라고요. 중간 진행 상황이 좀 더 잘 공유되면 좋겠습니다.'),\n",
              " Document(metadata={'source': 'voc_example.txt'}, page_content='[고객15]\\n설명서가 너무 기술적인 용어로만 되어 있어서 일반 소비자가 이해하기 힘듭니다. 쉬운 용어로 바꿔주세요.')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 임베딩 생성 및 벡터DB 저장\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
        "\n",
        "# 4. 기본 Retriever 설정\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "RPhvH_pQo7cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5️. Contextual Compression 적용\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")  # 압축에 사용할 LLM\n",
        "compressor = LLMChainExtractor.from_llm(llm)  # LLM 기반 문서 압축기\n",
        "compressed_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,  # 이 부분이 수정됨 (compressor -> base_compressor)\n",
        "    base_retriever=retriever,\n",
        ")\n",
        "\n",
        "# 6️. RAG QA 시스템 구축\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=compressed_retriever)"
      ],
      "metadata": {
        "id": "qf0qmRTZlu1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
      ],
      "metadata": {
        "id": "h9SDFk9CphbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7️. 질문 입력 후 응답 확인\n",
        "query = \"고객 VOC에서, 배송과 관련된 문제를 언급한 고객 피드백에 대해 정리해주세요.\"\n",
        "response = qa_chain.run(query)\n",
        "\n",
        "print(\"💡 답변:\", response)\n",
        "\n",
        "# retrieval 결과 비교\n",
        "print(\"\\n\\n##### normal retriever #####\")\n",
        "pretty_print_docs(retriever.invoke(query))\n",
        "\n",
        "print(\"\\n\\n##### compressed retriever #####\")\n",
        "pretty_print_docs(compressed_retriever.invoke(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKsmbs73nOt8",
        "outputId": "4bd86e9c-ad69-4d84-a70f-54e51500a632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 답변: 고객 VOC에서 배송과 관련된 문제를 언급한 고객 피드백은 다음과 같습니다:\n",
            "\n",
            "1. **배송 준비 상태**: 고객14는 주문 후 배송 준비 상태에서 며칠간 대기한 뒤 갑자기 발송되었다고 언급하며, 중간 진행 상황을 더 잘 공유해주길 요청했습니다.\n",
            "\n",
            "2. **배송 속도**: 고객1은 배송이 너무 느리다고 불만을 표하며, 일주일이 걸렸다고 언급했습니다. 이러한 상황이 계속된다면 다른 쇼핑몰을 이용할 것이라고 경고했습니다.\n",
            "\n",
            "3. **배송 박스 크기**: 고객10은 배송 박스가 너무 커서 불편하다고 언급하며, 작은 물건 하나를 보내는데 큰 상자를 사용하는 것에 대해 의문을 제기했습니다.\n",
            "\n",
            "\n",
            "##### normal retriever #####\n",
            "Document 1:\n",
            "\n",
            "[고객14]\n",
            "주문 후 배송 준비 상태로 며칠이나 있다가 갑자기 발송되더라고요. 중간 진행 상황이 좀 더 잘 공유되면 좋겠습니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "[고객1]\n",
            "배송이 너무 느립니다. 일주일이나 걸렸어요. 이런 식이면 다음부터는 다른 쇼핑몰을 이용해야 할 것 같네요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "[고객11]\n",
            "제품은 만족스러운데 설명서에 오타가 많아서 신뢰가 떨어졌습니다. 검수 좀 철저히 해주세요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "[고객4]\n",
            "제품은 괜찮은데 고객센터 연결이 너무 어렵습니다. 10번 넘게 전화해서 겨우 연결했어요. 상담원은 친절했지만 대기 시간이 너무 길었습니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 5:\n",
            "\n",
            "[고객10]\n",
            "배송 박스가 너무 커서 불편했습니다. 작은 물건 하나 보내는데 왜 이렇게 큰 상자를 쓰는지 모르겠어요.\n",
            "\n",
            "\n",
            "##### compressed retriever #####\n",
            "Document 1:\n",
            "\n",
            "[고객14] 주문 후 배송 준비 상태로 며칠이나 있다가 갑자기 발송되더라고요. 중간 진행 상황이 좀 더 잘 공유되면 좋겠습니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "[고객1]  \n",
            "배송이 너무 느립니다. 일주일이나 걸렸어요. 이런 식이면 다음부터는 다른 쇼핑몰을 이용해야 할 것 같네요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "배송 박스가 너무 커서 불편했습니다. 작은 물건 하나 보내는데 왜 이렇게 큰 상자를 쓰는지 모르겠어요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7️. 질문 입력 후 응답 확인\n",
        "query = \"상품 설명과 관련된 이슈가 있는 피드백만 요약하려고 합니다. 어떤 피드백이 해당되며, 요약된 핵심 내용은 무엇인가요?\"\n",
        "response = qa_chain.run(query)\n",
        "\n",
        "print(\"💡 답변:\", response)\n",
        "\n",
        "# retrieval 결과 비교\n",
        "print(\"\\n\\n##### normal retriever #####\")\n",
        "pretty_print_docs(retriever.invoke(query))\n",
        "\n",
        "print(\"\\n\\n##### compressed retriever #####\")\n",
        "pretty_print_docs(compressed_retriever.invoke(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4SEhOgCn0ov",
        "outputId": "0876ff70-2df9-4a9c-944c-f7a0b92d0680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 답변: 상품 설명과 관련된 이슈가 있는 피드백은 다음과 같습니다:\n",
            "\n",
            "1. **고객9**:\n",
            "   - 제품 설명서가 너무 간단하여 기능을 제대로 알 수 없음.\n",
            "   - 설명서에 오타가 많아 신뢰가 떨어짐. 검수가 필요함.\n",
            "\n",
            "2. **고객8**:\n",
            "   - 설명서가 외국어로만 되어 있어 이해하기 어려움. 한글 설명서 요청.\n",
            "   - 설명서에 나와 있는 기능이 실제 제품에는 없음. 반품 요청 절차가 복잡함.\n",
            "   - 설명서가 불친절하고 사용법이 어렵다고 느낌.\n",
            "\n",
            "**핵심 내용 요약**:\n",
            "- 제품 설명서의 간결함과 오타 문제로 인해 고객들이 기능을 이해하기 어렵고 신뢰를 잃고 있음.\n",
            "- 외국어 설명서로 인해 이해의 어려움이 있으며, 한글 설명서가 필요함.\n",
            "- 설명서와 실제 제품 간의 불일치로 인해 반품 요청이 복잡하다고 느끼고 있음.\n",
            "\n",
            "\n",
            "##### normal retriever #####\n",
            "Document 1:\n",
            "\n",
            "[고객9]\n",
            "제품 설명서가 너무 간단해서 어떤 기능이 있는지 제대로 알 수 없었습니다. 상세한 설명이 필요합니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "[고객11]\n",
            "제품은 만족스러운데 설명서에 오타가 많아서 신뢰가 떨어졌습니다. 검수 좀 철저히 해주세요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "[고객8]\n",
            "설명서가 외국어로만 되어 있어서 내용을 이해하기 어려웠습니다. 한글 설명서도 같이 제공해 주세요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "[고객5]\n",
            "설명서에 나와 있는 기능이 실제 제품에는 없네요. 사기당한 기분입니다. 반품 요청하고 싶은데 절차가 너무 복잡합니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 5:\n",
            "\n",
            "[고객2]\n",
            "제품 포장은 잘 되어 있었지만, 설명서가 너무 불친절합니다. 사용법이 이해가 안 가서 검색해봤어요. 초보자 입장에선 너무 어렵습니다.\n",
            "\n",
            "\n",
            "##### compressed retriever #####\n",
            "Document 1:\n",
            "\n",
            "[고객9] 제품 설명서가 너무 간단해서 어떤 기능이 있는지 제대로 알 수 없었습니다. 상세한 설명이 필요합니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "제품은 만족스러운데 설명서에 오타가 많아서 신뢰가 떨어졌습니다. 검수 좀 철저히 해주세요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "[고객8] 설명서가 외국어로만 되어 있어서 내용을 이해하기 어려웠습니다. 한글 설명서도 같이 제공해 주세요.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "[고객5]\n",
            "설명서에 나와 있는 기능이 실제 제품에는 없네요. 사기당한 기분입니다. 반품 요청하고 싶은데 절차가 너무 복잡합니다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 5:\n",
            "\n",
            "제품 포장은 잘 되어 있었지만, 설명서가 너무 불친절합니다. 사용법이 이해가 안 가서 검색해봤어요. 초보자 입장에선 너무 어렵습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u1zDl2A5n8NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습과제\n",
        "\n",
        "- 주어진 논문 텍스트에서, 정책 제안과 관련된 내용만 추출해 핵심적으로 요약해보세요.\n",
        "(힌트: 결론 부분을 중심으로 확인)\n",
        "\n",
        "- \"미세먼지와 건강의 관계\"에 대한 핵심 연구 결과만 2~3줄로 압축하여 요약하세요.\n",
        "(불필요한 연구 설계나 데이터 출처는 제외)"
      ],
      "metadata": {
        "id": "jOiRpA0lsng0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/FingerPointLab/llm-lecture-materials/refs/heads/main/paper_example.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM3ZWLEnsolU",
        "outputId": "793dc2f2-c068-4eef-8dd5-0d82a8fad7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 10:29:59--  https://raw.githubusercontent.com/FingerPointLab/llm-lecture-materials/refs/heads/main/paper_example.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1603 (1.6K) [text/plain]\n",
            "Saving to: ‘paper_example.txt’\n",
            "\n",
            "\rpaper_example.txt     0%[                    ]       0  --.-KB/s               \rpaper_example.txt   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-24 10:29:59 (22.1 MB/s) - ‘paper_example.txt’ saved [1603/1603]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 로딩\n",
        "loader = TextLoader('paper_example.txt')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "UHY2LUZStHOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 텍스트 분할 (Chunking)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10, separators=[\"\\n\\n\"])\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0253324-57b7-4336-dfba-7528847b311f",
        "id": "KISuM3eJtHOm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'paper_example.txt'}, page_content='\\n[초록(Abstract)]\\n본 연구는 미세먼지 농도가 도시민의 건강에 미치는 영향을 실증적으로 분석하였다. 2018년부터 2022년까지의 대기질 자료와 병원 진료 데이터를 바탕으로 패널 회귀모형을 구축하였으며, PM2.5의 농도가 높을수록 호흡기 질환 발생률이 유의하게 증가하는 것으로 나타났다.'),\n",
              " Document(metadata={'source': 'paper_example.txt'}, page_content='\\n\\n[서론(Introduction)]\\n최근 몇 년간 미세먼지에 대한 관심이 급증하고 있으며, 정부에서도 다양한 대책을 발표하고 있다. 그러나 실제로 미세먼지가 건강에 어떤 영향을 미치는지는 아직 논란이 많다. 이에 본 연구는 실증적 데이터를 활용하여 미세먼지와 건강 간의 상관관계를 규명하고자 한다.'),\n",
              " Document(metadata={'source': 'paper_example.txt'}, page_content='\\n\\n[방법(Methodology)]\\n본 연구에서는 환경부에서 제공하는 전국 17개 시도의 대기질 측정 데이터를 활용하였다. 또한 건강보험심사평가원에서 제공하는 병원 진료 기록을 기반으로 질병 발생률을 집계하였다. 분석에는 고정효과 모형과 다중회귀모형을 적용하였다.'),\n",
              " Document(metadata={'source': 'paper_example.txt'}, page_content='\\n\\n[결과(Results)]\\nPM2.5의 평균 농도가 10㎍/㎥ 증가할 때마다 호흡기 질환 진료율은 약 5.2% 증가하였다. 특히, 어린이와 노인 집단에서 그 효과가 더 뚜렷하게 나타났다.'),\n",
              " Document(metadata={'source': 'paper_example.txt'}, page_content='\\n\\n[결론(Conclusion)]\\n미세먼지는 호흡기 건강에 유의미한 영향을 미치며, 특히 취약 계층에 대한 보호가 필요함을 시사한다. 정부는 실효성 있는 정책 수립과 함께 지속적인 모니터링 체계를 마련해야 할 것이다.\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 임베딩 생성 및 벡터DB 저장\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
        "\n",
        "# 4. 기본 Retriever 설정\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "Mi8r8O4btHOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5️. Contextual Compression 적용\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")  # 압축에 사용할 LLM\n",
        "compressor = LLMChainExtractor.from_llm(llm)  # LLM 기반 문서 압축기\n",
        "compressed_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,  # 이 부분이 수정됨 (compressor -> base_compressor)\n",
        "    base_retriever=retriever,\n",
        ")\n",
        "\n",
        "# 6️. RAG QA 시스템 구축\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=compressed_retriever)"
      ],
      "metadata": {
        "id": "wrSPrVdctHOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
      ],
      "metadata": {
        "id": "NCLNXTCMtHOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7️. 질문 입력 후 응답 확인\n",
        "query = \"아래 논문 텍스트에서, 정책 제안과 관련된 내용만 추출해 핵심적으로 요약해보세요.\"\n",
        "response = qa_chain.run(query)\n",
        "\n",
        "print(\"💡 답변:\", response)\n",
        "\n",
        "print(\"##### normal retriever #####\")\n",
        "pretty_print_docs(retriever.invoke(query))\n",
        "\n",
        "print(\"##### compressed retriever #####\")\n",
        "pretty_print_docs(compressed_retriever.invoke(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202ec6c6-a699-427d-fd39-9702be852891",
        "id": "kJQOV1E0tHOq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 답변: 논문에서는 정부가 미세먼지로 인한 호흡기 건강 영향을 최소화하기 위해 실효성 있는 정책을 수립해야 하며, 취약 계층을 보호하기 위한 지속적인 모니터링 체계를 마련할 필요성이 강조되고 있습니다.\n",
            "[normal retriever]\n",
            "Document 1:\n",
            "\n",
            "\n",
            "\n",
            "[결론(Conclusion)]\n",
            "미세먼지는 호흡기 건강에 유의미한 영향을 미치며, 특히 취약 계층에 대한 보호가 필요함을 시사한다. 정부는 실효성 있는 정책 수립과 함께 지속적인 모니터링 체계를 마련해야 할 것이다.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "\n",
            "\n",
            "[서론(Introduction)]\n",
            "최근 몇 년간 미세먼지에 대한 관심이 급증하고 있으며, 정부에서도 다양한 대책을 발표하고 있다. 그러나 실제로 미세먼지가 건강에 어떤 영향을 미치는지는 아직 논란이 많다. 이에 본 연구는 실증적 데이터를 활용하여 미세먼지와 건강 간의 상관관계를 규명하고자 한다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "\n",
            "\n",
            "[방법(Methodology)]\n",
            "본 연구에서는 환경부에서 제공하는 전국 17개 시도의 대기질 측정 데이터를 활용하였다. 또한 건강보험심사평가원에서 제공하는 병원 진료 기록을 기반으로 질병 발생률을 집계하였다. 분석에는 고정효과 모형과 다중회귀모형을 적용하였다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "\n",
            "[초록(Abstract)]\n",
            "본 연구는 미세먼지 농도가 도시민의 건강에 미치는 영향을 실증적으로 분석하였다. 2018년부터 2022년까지의 대기질 자료와 병원 진료 데이터를 바탕으로 패널 회귀모형을 구축하였으며, PM2.5의 농도가 높을수록 호흡기 질환 발생률이 유의하게 증가하는 것으로 나타났다.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 5:\n",
            "\n",
            "\n",
            "\n",
            "[결과(Results)]\n",
            "PM2.5의 평균 농도가 10㎍/㎥ 증가할 때마다 호흡기 질환 진료율은 약 5.2% 증가하였다. 특히, 어린이와 노인 집단에서 그 효과가 더 뚜렷하게 나타났다.\n",
            "\n",
            "\n",
            "[compressed retriever]\n",
            "Document 1:\n",
            "\n",
            "미세먼지는 호흡기 건강에 유의미한 영향을 미치며, 특히 취약 계층에 대한 보호가 필요함을 시사한다. 정부는 실효성 있는 정책 수립과 함께 지속적인 모니터링 체계를 마련해야 할 것이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWScXLRXtRfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}